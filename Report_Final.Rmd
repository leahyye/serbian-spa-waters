---
title: "Serbian Spa Waters Report"
author: "Leah Ye (300651931), Harry Philpott (300667756),


Claude Butler (300651409), Elizabeth Myers (300641471)"
output: 
  bookdown::pdf_document2:
    latex_engine: xelatex
bibliography: STAT394_references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE
)
set.seed(1234, kind="Mersenne-Twister")
library(dplyr)
library(knitr)
library(GGally)
library(ggplot2)
library(tidyr)
library(corrplot)
library(kableExtra)
library(plotly)
library(MASS)
library(e1071)
library(caret)
library(wesanderson)
library(psych)
```

# **Introduction**

This project is based on an article by Tanasković, Golobocanin, and Miljević [-@TANASKOVIC2012226], in which the authors analyzed hydrochemical data for mineral and thermal waters in Serbian territory. They used principal component analysis (PCA) and hierarchical cluster analysis (HCA) to characterize the chemical composition and natural radioactivity of these water samples, understand the relationships between the variables measured, and classify the waters with respect to their geotectonic units. PCA revealed four latent factors that accounted for 74.2% of the variability among the observations. Two of these four PCs are based on measures of mineralisation of the components of the host rock, and the other two are based on variables that are indicative of natural radioactivity. The results of PCA achieved a total correct classification of 83.3% for predefined geotectonic units, and the dendrogram of HCA classified the samples into four major groups and eleven subgroups.

# **Methodology**

The Serbian Spa Waters Dataset contains 30 observations (sites), with 15 columns. The data types and units are detailed in Table \@ref(tab:columnsTable).

```{r, echo = FALSE, results = 'asis'}
columns <- data.frame(
  Variable = c("ID", "Source", "geoStruct", "T", "pH", "EC", "TS",
               "Ca$^{2+}$", "Mg$^{2+}$", "Na$^{+}$", "K$^{+}$", "Cl$^{-}$", 
               "SO$^{2-}_4$", "HCO$^{-}_3$", "SiO$_2$"),
  Description = c("Index of each observation", "Name of the spa or spring",
                  "Geological structure", "Temperature", 
                  "pH level (Acidity/Alkalinity)", "Electrical conductivity",
                  "Total dissolved solids", "Calcium", "Magnesium",
                  "Sodium", "Potassium", "Chlorine", "Sulfate", "Bicarbonate",
                  "Silica, dissolved silicon dioxide"),
  Units = c("", "", "", "$^\\circ$C", "", "$\\mu$S/cm", "g/L", "mg/L", "mg/L",
            "mg/L", "mg/L", "mg/L", "mg/L", "mg/L", "mg/L"),
  DataType = c("Integer", "Character", "Integer", "Numerical", "Numerical", 
               "Integer", "Numerical", "Numerical", "Numerical", "Numerical",
               "Numerical", "Numerical", "Numerical", "Numerical", "Numerical"),
  stringsAsFactors = FALSE
)

kable(columns,
      caption = "Description of All Columns in the Dataset \\label{tab:columnsTable}",
      align = c("l", "l", "c", "l"),
      booktabs = TRUE,
      escape = FALSE) %>%  
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%
  row_spec(1:nrow(columns), extra_css = "font-family: serif; line-height: 1.2;") %>%
  column_spec(1:ncol(columns), extra_css = "font-family: serif;")
```

Samples were taken from four different geological structures. The names of the structures and the integer values given in the dataset can be found in Table \@ref(tab:geoStructTable).

```{r, echo=FALSE, results='asis'}
basins <- data.frame(
  Integer = 1:4,
  Name = c("Hydrogeological basins", "Karstic terrains", 
           "Volcanogenic massifs", "Metamorphic regions"),
  stringsAsFactors = FALSE
)

kable(basins,
      caption = "Types of Geological Units \\label{tab:geoStructTable}",
      align = c("c", "l"),
      booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%
  row_spec(1:nrow(basins), extra_css = "font-family: serif; line-height: 1.2;") %>%
  column_spec(1:ncol(basins), extra_css = "font-family: serif;")
```


Ions $\mathrm{(HCO_3^-, Ca^{2+}, Mg^{2+}, Na^+, K^+, Cl^-, SO_4^{2-}, SiO_2)}$ were analysed in the laboratories of the Institute of Public Health of Serbia. Titration methods were applied to measure alkalinity of $Ca^{2+}$ and $Mg^{2+}$. Concentrations of $Na^+$ and $K^+$ were determined by atomic absorption spectrophotometry.

Six radiological variables from the original paper were not publicly available. This unfortunate omission does affect comparisons with those results, as we can not be sure what differences are due to our methodology and which are due to the reduced set of variables. The details of the missing variables are listed in Table \@ref(tab:isotopeTable).

```{r, echo=FALSE, results='asis'}
isotopes <- data.frame(
  Variable = c("GA", "GB", "$^{238}$U", "$^{228}$R", "$^{226}$R", "$^{40}$K"),
  Description = c("Gross alpha activities", "Gross beta activities", 
                  "Uranium isotope", "Radium isotope", "Radium isotope", "Potassium isotope"),
  Units = c("mBq/L", "", "", "", "", ""),
  stringsAsFactors = FALSE
)

kable(isotopes,
      caption = "Radioactive Isotopes Measured in Serbian Spa Waters \\label{tab:isotopeTable}",
      align = c("c", "l", "c"),
      booktabs = TRUE,
      escape = FALSE) %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%
  row_spec(1:nrow(isotopes), extra_css = "font-family: serif; line-height: 1.2;") %>%
  column_spec(1:ncol(isotopes), extra_css = "font-family: serif;")
```

Where Hyodrological Basins and Karstic terrains have 5 observations each, Volcanogen Massifs has 14 observations, and Metamorphic Regions has 6 observations. This is an unbalanced dataset since there are varying observations per group.

There are no duplicates, missing data, zeros, negatives, NAs or NULL values in the dataset.

Exploratory data analysis will assess basic summary statistics of the data. We will utilise graphical analysis of box plots and a QQ plot to check basic assumptions of  required for further analysis, such as both univariate and multivariate normality. A correlation plot and Principal Component Analysis (PCA) will be performed to further investigate the relationships between variables. We will also identify outliers and surprising observations within the data, using standard deviation as well as Mahalanobis distance, and in terms of the principal components.

Our initial exploratory data analysis revealed that the dataset was characterised by high variability and right-skewedness, leading us to perform a log transformation on the data and use these transformed variables for our analysis.

We will assess the validity of the paper's geological structure groups based on the data, using the methods of MANOVA and Naive Bayes Classifier, as our EDA revealed that the data violates the assumptions for Linear Discriminant Analysis.

We will then use Factor Analysis to attempt to improve on the paper's model 
parsimony; factor analysis is better for model selection since it doesn't 
include noise like PCA, and maintains parsimony. 

# **Results and Discussion**

## EDA

```{r echo=FALSE}
data <- read.csv("serbianspawater.csv")
```

```{r echo=FALSE}
# Select numeric columns
numeric_cols <- data[sapply(data, is.numeric) & !(names(data) %in% c("idNum", "geoStruct"))]

# Create summary table
summary <- data.frame(
  Variable = names(numeric_cols),
  Mean     = round(sapply(numeric_cols, mean), 2),
  Median   = round(sapply(numeric_cols, median), 2),
  SD       = round(sapply(numeric_cols, sd), 2),
  Min      = round(sapply(numeric_cols, min), 2),
  Max      = round(sapply(numeric_cols, max), 2),
  row.names = NULL
)

# Format summary to show two decimal places
summary_formatted <- summary
summary_formatted[, 2:6] <- lapply(summary[, 2:6], function(x) sprintf("%.2f", x))

# Display table
kable(summary_formatted, 
      caption = "Summary Statistics for Numeric Columns", 
      align = c("l", "r", "r", "r", "r", "r"),
      booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position"),
                full_width = FALSE) %>%
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%
  row_spec(1:nrow(summary_formatted), extra_css = "font-family: serif; line-height: 1.2;") %>%
  column_spec(1:ncol(summary_formatted), extra_css = "font-family: serif;")
```

This dataset is characterized by high variability (Table 4). This is likely due to the 
different water sources. pH is more consistent, ranging from neutral (6.5) to 
slightly basic (9.0), which are fairly typical values for water in nature. The 
range of temperatures recorded in this dataset is from 14.40 to 95.00 degrees 
celcius. The large standard deviation confirms that there is a lot of 
variability in temperature. Some of these water sources are near boiling 
temperatures. Electrical conductivity also has a very large range, from 110.00 
to 5100.00 $\mu$S/cm. This indicates that some water samples have a lot of 
dissolved ions, leading to high conductivity. This measure is roughly 
proportional to the total dissolved solids, which also displays a large range, 
from 0.10 to 6.20. The maximum is more than three standard deviations above the 
mean, suggesting right-skew and surprising observations. There are eight major 
ions in this dataset: Calcium ($\mathrm{Ca^{2+}}$), 
Magnesium ($\mathrm{Mg^{2+}}$), Sodium ($\mathrm{Na^+}$), 
Potassium ($\mathrm{K^+}$), Chloride ($\mathrm{Cl^-}$), 
Sulfate ($\mathrm{SO_4^{2-}}$), Bicarbonate ($\mathrm{HCO_3^-}$), and 
Silica ($\mathrm{SiO_2}$). All of them are characterized by high variability, 
often with right-skew. Calcium has a mean of 61.02 and a range of 4.00 to 
178.00. The maximum is three standard deviations above the mean. Magnesium has 
an average of 44.46 and a range of 0.10 to 293.00, with a maximum that is four 
standard deviations above the mean. Sodium has a high average of 447.09, and a 
high maximum of 2280.00, which is again three standard deviations above the 
mean. Potassium is not as elevated with a mean of 16.58, but it is still 
somewhat variable. Chloride has a particularly extreme maximum of 1560.00, 
which is five standard deviations above its mean of 108.70. Sulfate has a mean 
of 57.53 and a maximum of 486.00, which is four standard deviations above the 
mean. Bicarbonate has a very high mean of 1297.91, and the maximum reaches a 
staggering 3538.00. The last major ion is Silica, which has a mean of 38.73, but 
a range from 2.00 to 120.00. To summarize, the whole dataset show high 
variability and pervasive right-skewness. The chemical composition of the water
samples is largely dominated by bicarbonate, with sodium and chloride also 
reaching very high values for some samples.

```{r corrplot, fig.cap="Correlation matrix of Serbian spa water variables", include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.asp=0.8}
par(family = "Times")
cor_mat <- cor(numeric_cols, use = "pairwise.complete.obs", method = "pearson")
corrplot(cor_mat,
         method = "color",        
         type = "upper",          
         order = "hclust",        
         addCoef.col = "black",   
         number.cex = 0.7,        
         tl.col = "black",        
         tl.srt = 45,             
         diag = FALSE, 
         col = colorRampPalette(c("#046C9A","white","#FD6467"))(200)
)
``` 

The correlation plot in Figure \@ref(fig:corrplot) reveals a few very highly correlated pairs of variables. Electrical conductivity, total solids, sodium, potassium, and chloride form a strongly correlated cluster, with Pearson's Correlation Coefficients from 0.37 to 0.96.  This indicates that they vary together across spa waters. Electrical conductivity in particular is directly related to the total dissolved solids in water, as more salts and minerals in the water increases the amount of ions, which in turn increase electrical conductivity.   
In contrast, pH shows moderate negative correlations with several ions (e.g., C$\mathrm{Ca^{2+}}$, $\mathrm{Mg^{2+}}$, $\mathrm{HCO_3^-}$), suggesting  different geochemical influences. Overall, the matrix highlights both tightly linked chemical groups and variables with weaker or opposing trends.

```{r boxplots, fig.cap="Boxplots of Z-Scored Variables", echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE, dpi=100, include=TRUE}
# Select numeric features for scaling 
X <- data[, 3:14]                    #all numerical categories
X <- as.data.frame(scale(X))         # z-scores per variable
X$.row <- 1:nrow(X)

# pivot long for plotting
box_long <- pivot_longer(           
  X,
  cols = - .row,
  names_to = "variable",
  values_to = "value"
)

colors <- c(
  wes_palette("Darjeeling1"),     
  wes_palette("FantasticFox1"),
  wes_palette("Darjeeling2")    
)

colors <- colors[1:12]

# boxplots on a common axis (z-scored)
ggplot(box_long, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot(notch = TRUE, outlier.alpha = 0.6, na.rm = TRUE) +
  coord_flip() +
  scale_fill_manual(values = colors) + 
  labs(x = NULL, 
       y = "Scaled value (z-score)") +
  theme_minimal(base_family = "Times") + 
  theme(
    plot.title = element_text(face = "bold", size = 22),  
    axis.title = element_text(size = 20),                  
    axis.text.x = element_text(size = 16), 
    axis.text.y = element_text(size = 16),
    panel.grid.major = element_line(color = "grey80", size = 0.3),
    panel.grid.minor = element_blank(),
    legend.position = "none"
  )
```

Variables were standardised to z-scores to allow direct comparison despite differing measurement units. The boxplots in Figure \@ref(fig:boxplots) show that some features (e.g. $\mathrm{Na^+}$, $\mathrm{Cl^-}$, $\mathrm{HCO_3^-}$) have greater variability and distinct outliers, while others remain tightly clustered around the mean. This highlights which chemical measures are most heterogeneous across the spa waters. However, all variables in the boxplot have a non-symmetrical shape and contain outliers, indicating that a log transformation is necessary.

```{r multivariateNormal, fig.cap="QQ-plot of MANOVA residuals", include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, fig.asp=0.8}
# Fit MANOVA model using geoStruct as grouping
fit <- manova(as.matrix(X) ~ data$geoStruct)
# Extract residuals
res <- residuals(fit)
# Mahalanobis distances of residuals
mu_res <- colMeans(res)
S_res  <- cov(res)
d2_res <- mahalanobis(res, center = mu_res, cov = S_res)

# Degrees of freedom = number of variables
df <- ncol(res)

# QQ-plot
par(family = "serif",
    cex.main = 2,
    cex.lab = 2,
    cex.axis = 1.8,
    mar = c(5, 6, 4, 2))

qqplot(qchisq(ppoints(nrow(res)), df = df), d2_res,
       xlab = expression(paste(chi^2, " quantiles")),
       ylab = expression(paste("Ordered residual ", d[M]^2)))
abline(0,1,col="#046C9A", lwd = 2)
```

The QQ-plot of MANOVA residual Mahalanobis distances in Figure \@ref(fig:multivariateNormal) against the theoretical $\chi^2$ distribution provides a diagnostic for assessing multivariate normality. If the residuals were perfectly normal, the points would lie close to the 45° line. In this case, the points deviate fairly evenly across the range of  quantiles, rather than only at one end, indicating that the residuals are not an exact match to the multivariate Gaussian model. The upper tail in particular shows noticeable departures, with the largest residuals exceeding the expected $\chi^2$ quantiles, which indicates potential heavy-tailed behaviour or the presence of outliers. This means the assumption of multivariate normality is not fully satisfied.

```{r, echo=FALSE}
# Log transforming numeric variables and adding them into dataset as new columns
data$log.tempCels <- log(data$tempCels)
data$log.pH <- log(data$pH)
data$log.elec.Cond <- log(data$elecCond)
data$log.totSolid <- log(data$totSolid)
data$log.Ca2 <- log(data$Ca2)
data$log.Mg2 <- log(data$Mg2)
data$log.Na <- log(data$Na)
data$log.K <- log(data$K)
data$log.Cl <- log(data$Cl)
data$log.SO2 <- log(data$SO2)
data$log.HCO <- log(data$HCO)
data$log.SiO <- log(data$SiO)
```

After performing a log transformation of the variables, we recheck the univariate and multivariate normality of the data. First we can inspect the boxplots in Figure \@ref(fig:boxplotsLogTransformed) to begin. 

```{r boxplotsLogTransformed, fig.cap="Boxplots of Log-Transformed Z-Scored Variables", echo=FALSE, warning=FALSE, message = FALSE}
X.log <- data[, 16:27]                    # all log transformed numerical variables
X.log <- as.data.frame(scale(X.log))         # z-scores per variable
X.log$.row <- 1:nrow(X.log)

box_long <- pivot_longer(           
  X.log,
  cols = - .row,
  names_to = "variable",
  values_to = "value"
)

# not z-scored
ggplot(box_long, aes(x = variable, y = value, fill = variable)) +
  geom_boxplot(notch = TRUE, outlier.alpha = 0.6, na.rm = TRUE) +
  coord_flip() +
  scale_fill_manual(values = colors) + 
  labs(x = NULL, y = "Scaled value (z-score)") +
  theme_minimal(base_family = "Times") + 
  theme(
    panel.grid.major = element_line(color = "grey80", size = 0.3),
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold", size = 16),
    axis.text = element_text(size = 12),
    legend.position = "none")
```

The boxplots are far more symmetric than with the untransformed data, showing more conformity with the normal distribution. However, we can clearly see the presence of outliers, particularly with the variable $\mathrm{Mg^{2+}}$ which has four observations at least two standard deviations below the mean.

```{r QQplotLogTransorm, fig.cap="QQ-plot of MANOVA (Log-Transformed) Residuals", echo=FALSE, warning=FALSE, message = FALSE}
X_log_matrix <- as.matrix(X.log[, !names(X.log) %in% ".row"])

# Fit MANOVA model
fit_log <- manova(X_log_matrix ~ data$geoStruct)
res_log <- residuals(fit_log)

# Reusing Prev code
# Mahalanobis distances of residuals
mu_res_log <- colMeans(res_log)
S_res_log  <- cov(res_log)
d2_res_log <- mahalanobis(res_log, center = mu_res_log, cov = S_res_log)

# Degrees of freedom = number of variables
df_log <- ncol(res_log)

# QQ-plot
par(family = "serif",
    cex.main = 2,
    cex.lab = 1.8,
    cex.axis = 1.8,
    mar = c(5, 6, 4, 2))

qqplot(qchisq(ppoints(nrow(res_log)), df = df_log), d2_res_log,
       xlab = expression(paste(chi^2, " quantiles")),
       ylab = expression(paste("Ordered residual ", d[M]^2)))
abline(0,1,col="#046C9A", lwd = 2)
```

The QQ-plot of MANOVA residual Mahalanobis distances in Figure \@ref(fig:corrplot) shows that the points follow the line more closely after the log transformation.  Deviations still remain, particularly at high values, but the log-transformed data much more closely follow a multivariate normal distribution. We will continue with the log-transformed data while recognizing that this violates the assumptions of LDA, PCA, and MANOVA. 

## PCA

Moving on to PCA, we can see in Table \@ref(tab:PCA-summary-table) that PC1 explains a lot of the variance (around half, 48.41%). PC2 explains about a further fifth (17.94%). PC3 and PC4 explain a further 10.83% and 7.79% respectively, and these 4 PCs cumulatively account for 84.97% of the overall variance. From PC5 and onwards, each PC explains less than 7% of the extra variance. The elbow plot in Figure \@ref(fig:screeplot) displays this flattening as the effect of each PC becomes smaller and smaller. Based on this plot, using 4 Principal Components will be sufficient in the model.

```{r screeplot, fig.cap="PCA Elbow Plot", echo=FALSE, warning=FALSE, message=FALSE}
pca_fit <- prcomp(X_log_matrix, center=TRUE, scale. = TRUE) # apply pca on relevant explanatory numerical columns 

# variance explained
var_explained <- pca_fit$sdev^2 / sum(pca_fit$sdev^2)

# data frame for ggplot
df <- data.frame(
  PC = seq_along(var_explained),
  Variance = var_explained
)

ggplot(df, aes(x = PC, y = Variance)) +
  geom_line(color = "#046C9A", linewidth = 1) +
  geom_point(size = 3, color = "#046C9A") +
  labs(
    title = "Scree Plot",
    x = "Principal Component",
    y = "Proportion of Variance Explained"
  ) +
  theme_minimal(base_family = "serif") +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14)
  )
```

```{r PCA-summary-table, fig.cap="Summary of Principal Components", echo=FALSE, message=FALSE, warning=FALSE}
# Extract summary and convert to data frame
pca_summary <- summary(pca_fit)$importance
pca_df <- as.data.frame(round(pca_summary, 4))  # Round for readability
pca_df <- t(pca_df)  # Transpose so PCs are rows

# Convert row names to a column so we can bold selectively
pca_df <- as.data.frame(pca_df)
pca_df$PC <- rownames(pca_df)
rownames(pca_df) <- NULL
pca_df <- pca_df[, c(ncol(pca_df), 1:(ncol(pca_df)-1))]  # PC as first column

# Create LaTeX table with decimal alignment
kable(pca_df, format = "latex", booktabs = TRUE, align = "r", 
      caption = "Summary of Principal Components") %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%               # Bold first column (PC names)
  column_spec(2:ncol(pca_df), border_left = TRUE) %>% 
  # Align decimals using the LaTeX dcolumn package
  pack_rows("PCs", 1, nrow(pca_df)) %>%        # Optional grouping
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%
  row_spec(1:nrow(pca_df), extra_css = "font-family: serif;") %>%
  column_spec(1:ncol(pca_df), extra_css = "font-family: serif;") 
```

```{r fig.cap="Serbian Spa Variable Influence on Principal Components", echo=FALSE, message=FALSE, warning=FALSE}
# Prepare loadings
loadings <- pca_fit$rotation
loadings_df <- as.data.frame(loadings)
loadings_df$Variable <- rownames(loadings_df)
loadings_df <- loadings_df[, c("Variable", paste0("PC", 1:4))]
rownames(loadings_df) <- NULL

# Create table
kable(loadings_df, format = "latex", digits = 3, align = "r",
      caption = "Serbian Spa Variable Influence on Principal Components \\label{PCA-loadings-table") %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%                         # Bold variable names
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>% 
  row_spec(1:nrow(loadings_df), extra_css = "font-family: serif;") %>%
  column_spec(1:ncol(loadings_df), extra_css = "font-family: serif;")
```

Table \@red(tab:PCA-loadings-table) displays the influence of individual variables on the four principal components. In PC1, $HCO_3^-$ (0.388), $Na^+$ (0.345), elecCond (0.378), $K^+$ (0.376), and totSolid (0.367) have the highest influence. PC1 strongly correlates with variables relating to major ions and total dissolved content. From this, we can conclude that PC1 primarily captures the overall mineral content and ionic composition of the water. Samples with high PC1 scores have high mineralisation. In PC2, $Mg^{2+}$ (0.438), $Ca^{2+}$ (0.55), tempCels (-0.329), $SiO_2$ (-0.352), and $Na^+$ (-0.301), have the strongest influence. PC2 separates water with high calcium and magnesium from waters at higher temperatures. High levels of calcium and magnesium is what is referred to as hard water. This suggests that there is a difference between hard, cold waters and softer, warmer waters. In PC3, $SO_2$ (0.717) and tempCels (0.521) have the strongest influence. Waters that have more sulfate are also warmer. In PC4, $SiO_2$ (-0.611), $Cl^-$ (0.676) and tempCels (0.302) have the strongest influence. Waters with higher chlorine levels have less silicone and are warmer.

The first two principal components largely align with those found in the study, despite the difference between the variables we had access to. In the study, four latent factors were found to explain 74.2% of the variance- 10% less than what we achieved with four factors for only the hydrochemical variables. The study's first PC was also largely positively influenced by mineralisation, and accounted for 37.5% of the variance, whereas ours accounted for 48.4%. PC2 in the study accounted for 13.8%, while our PC2 accounted for 17.9%- in both cases, the second PC had high positive loadings on $Mg^{2+}$ and $Ca^{2+}$, reflecting on water hardness. The third and fourth principal components diverge from the study in our analysis- in the study, PC3 accounts for 10.3% of variance and is characterised by gross alpha activity and Ra-226. PC4 accounts for 12.4% of variation and is also characterised by measures of radioactivity, of  radionuclides U-238, Ra-228. Given our lack of radioactivity data, our third and fourth PCs are hydrochemical factors.

## Surprising observations

```{r fig.cap="Water sources with at least one variable > 3 standard deviations from the mean",echo=FALSE}
# Standardise numeric variables
X <- scale(data[, 3:14])

# Find any rows with at least one variable > 3 sd away
outliers <- which(apply(abs(X), 1, max) > 3)

# Show these "surprising" sites
surprising_sites <- data[outliers, c("waterSource", "tempCels", "elecCond", "totSolid",
                 "Na", "Cl", "HCO")]

kable(surprising_sites,
      format = "latex",
      caption = "Water sources with at least one variable > 3 standard deviations from the mean \\label{tab:outlierTable}",
      align = "c",
      digits = 2) %>%
  kable_styling(latex_options = "HOLD_position", full_width = FALSE, position = "center") %>%
  row_spec(0, bold = TRUE, extra_css = "font-family: serif;") %>%   # Bold header row
  row_spec(1:nrow(surprising_sites), extra_css = "font-family: serif;") %>% # Serif for data rows
  column_spec(1:ncol(surprising_sites), extra_css = "font-family: serif;")       
```

From the standardised $n=30$ observations, five springs are flagged as clear outliers (Table \@ref(tab:outlierTable)): Junakovic, Selters, Vranjska, Tulaska, and Veluce. Each of these sites has at least one measurement more than three standard deviations from the mean. Junakovic is extreme in electrical conductivity ($5100~\mu$S/cm) and total dissolved solids ($6.2$ g/L). Selters is distinguished by exceptionally high concentrations of sodium ($2280$ mg/L), chloride ($1560$ mg/L), and bicarbonate ($3360$ mg/L). Vranjska stands out for its near-boiling temperature ($95^\circ$C), while Tulaska and Veluce show unusually high bicarbonate levels relative to the rest of the dataset. These five cases are the most “surprising” when the dataset is examined variable by variable.

```{r pcaWithOutliers, fig.cap="PCA with Outliers Highlighted", echo=FALSE, message=FALSE, warning=FALSE}
# Mahalanobis distances
mu <- colMeans(X)
S  <- cov(X)
d2 <- mahalanobis(X, center = mu, cov = S)
cut <- qchisq(0.95, df = ncol(X))
outliers <- d2 > cut

# Add to PCA plot data
pca_plot_data <- data.frame(
  PC1 = pca_fit$x[, 1],
  PC2 = pca_fit$x[, 2],
  Geological_Group = as.factor(data$geoStruct),
  Water_Source = data$waterSource,
  Outlier = outliers
)

# Plot
ggplot(pca_plot_data, aes(x = PC1, y = PC2, color = Geological_Group)) +
  geom_point(size = 4, alpha = 0.8) +
  # Highlight outliers
  geom_point(data = subset(pca_plot_data, Outlier), 
             aes(x = PC1, y = PC2, color = Geological_Group), 
             shape = 21, fill = "yellow", size = 4, stroke = 1.2, show.legend = FALSE) +
  geom_text(data = subset(pca_plot_data, Outlier),
            aes(label = Water_Source),
            color = "black",
  size = 3.5, max.overlaps = 15, box.padding = 0.5, point.padding = 0.2) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.5) +
  stat_ellipse(level = 0.95, alpha = 0.7) +  
  labs(x = paste0("PC1 (", round(summary(pca_fit)$importance[2,1]*100, 1), "%)"),
    y = paste0("PC2 (", round(summary(pca_fit)$importance[2,2]*100, 1), "%)"),
    color = "Geological\nStructure"
  ) +
  theme_minimal() +
  scale_color_brewer(palette = "Set1") +
  theme(legend.position = "right")
```
Plotting the Mahalanobis distance against the first two principle components (Figure \@ref(fig:pcaWithOutliers)
gives a multivariate view of the outliers in terms of their overall chemical
composition rather than a single variable. Using the Mahalanobis distance with
a 95% Chi-Squared significance, another five sites were identified as outliers. They are plotted with yellow centers. 
These are the same five as previously identified as having extreme values for
individual variables, with the exception that Junakovic is no longer an outlier and Bujanovacka has replaced it.

```{r echo = FALSE}
outlier_table <- data.frame(
  Water_Source = data$waterSource[outliers],
  Geological_Group = data$geoStruct[outliers],
  Mahalanobis_Distance = round(d2[outliers], 2),
  PC1 = round(pca_fit$x[outliers, 1], 2),
  PC2 = round(pca_fit$x[outliers, 2], 2)
)

knitr::kable(
  outlier_table,
  caption = "Mahalanobis Outliers with PCA Scores \\label{tab:outliersPCAScores}",
  align = "c")%>%
  kable_styling(latex_options = "H", position = "center")
```

Bujanovacka and Tularska score highly along the first PC, as can be seen in Table \@ref(tab:outliersPCAScores). This indicates high mineralisation and ionisation in these samples, and is 
consistent with our earlier finding of Selters as having high concentrations 
of chloride, sodium, and bicarbonate and Tulaska having high concentrations of
sodium and bicarbonate. Veluce also scores highly on concentrations
of bicarbonate, giving it a relatively high score on PC1 but not as extreme.

Along PC2, Vranskja has a strong negative score. Temperature has a strong 
negative influence on PC2, and Vranskja stands out among the sites for its
extremely high temperature (near boiling, 95 $^{\circ}$C). 


## Factor Analysis

Factor analysis is a model estimation technique which deals with the assumptions of underlying causal structure, whereas PCA is a data transformation.It assumes that the covariation in the observed variables is due to the presence of one or more factors (latent variables) that exert causal influence on these observed variables. PCA does not make such assumptions but both PCA and FA do not have a dependent variable to be explained by independent variables. The hypothesis is therefore that there are unobserved variables that explain the observations.

```{r factorAdequacyTest, fig.cap="Factor Adequacy Test",echo=FALSE}
X.log <- X.log[, !names(X.log) == ".row"] # remove '.row' column

pvalues <- rep(0, 5) 
for(f in 1:5) {
  res <- try(factanal(X.log, factors = f), silent = TRUE) # get the p-values for each factor
  if(!inherits(res, "try-error")) {
    pvalues[f] <- res$PVAL
  }
}

ggplot(data.frame(Factors = 1:5, pvalues = pvalues), 
       aes(x = Factors, y = pvalues)) +
  geom_line(color = "#046C9A", size = 1) +
  geom_point(color = "#046C9A", size = 3) +
  labs(
    x = "Number of Factors",
    y = "p-value"
  ) +
  theme_minimal(base_family = "serif") +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14)
  )
```

The null and alternative hypotheses for each number of factors (k) are as follows:

$H_0:$ k factors are sufficient\
$H_1:$ More than k factors are needed

Given the hypotheses, we can see from the Factor Analysis Plot in Figure \@ref(fig:factorAdequacyTest) that a five-factor model is sufficiently complex to capture the underlying structure in the data, because the $p$-value is greater than 0.05. Four or less factors is not sufficient as the $p$-values are all less than 0.03.


```{r fig.cap="Factor Loadings from Factor Analysis", echo=FALSE}
faresult <- factanal(X.log, factors=5)
loadings_df <- as.data.frame(unclass(faresult$loadings))

loadings_df <- round(loadings_df, 3)

kable(loadings_df,
      caption = "Factor Loadings from Factor Analysis \\label{tab:FALoadings}",
      format = "latex",
      booktabs = TRUE,
      align = "c") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"),
                full_width = FALSE,
                font_size = 10) %>%
  row_spec(0, bold = TRUE)
```

The Factor Loadings in Table \@ref(tab:FALoadings) show that including factor five increases the cumulative explained variance to 82.4% of the total variance. Its individual loadings, however, are relatively low with a maximum of 0.379. Given this result, we decided to retain four factors for the vizualisation. 

```{r FADiagram, fig.cap="Factor Loadings Diagram", echo=FALSE }
fa.diagram(faresult$loadings, digits=4)
```

The red arrows indicate negative variables with negative loadings. The four factors that were identified by our analysis are as follows:

```{r fig.cap="Summary of Factor Analysis",echo=FALSE, escape=FALSE}
# Create a data frame with factor info
fa_summary <- data.frame(
  Factor = c("F1", "F2", "F3", "F4"),
  `Main Loadings` = c(
    "Total Solids (+), Electrical Conductivity (+), Na (+), HCO$_3$ (+), K (+), SiO$_2$ (+)",
    "Mg$^{2+}$ (+), Ca$^{2+}$ (+), pH (−), Temperature (−)",
    "Cl (+)",
    "SO$_4^{2-}$ (+)"
  ),
  Description = c(
    "Highly mineralised waters (high solidity and electrical conductivity)",
    "Hard, acidic, and cooler waters (Mg$^{2+}$ and Ca$^{2+}$ dominant)",
    "Chloric waters",
    "Sulfate-rich waters"
  ),
  stringsAsFactors = FALSE
)

# Display table
kable(fa_summary, format = "latex", booktabs = TRUE,
      caption = "Summary of Factor Analysis \\label{summaryFactors}") %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"), full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2, width = "7cm", extra_css = "font-family: serif;") %>%
  column_spec(3, width = "6cm", extra_css = "font-family: serif;")
```

The four-factor model explains 79% of the cumulative variance, compared to PCA, where four principal components explain 85%. Factor analysis is preferable for model selection because it isolates meaningful underlying structure while excluding noise, thus maintaining parsimony. In contrast, PCA required consideration of all 12 principal components to capture the variance structure of spa water chemistry, whereas factor analysis required only five or fewer factors to identify the main compositional patterns.

Factor analysis is better for model selection since it doesn't include noise like PCA (that's why PCA variance for 4 PCs was greater than FA 4 factors cumulative variance), and maintains parsimony. PCA had to consider all 12 Principal Components, whereas FA only had to look at 5 or less factors for determining the underlying structure of spa water composition.

## geoStruct Groups

```{r echo=FALSE}
# Check p value
manova_summary <- summary(fit_log, test = "Hotelling-Lawley")$stats

# Convert to a data frame
manova_df <- as.data.frame(manova_summary)
manova_df$Term <- gsub("^data\\$", "", rownames(manova_df))
manova_df[is.na(manova_df)] <- ""

# Reorder columns so 'Term' is first
manova_df <- manova_df[, c(ncol(manova_df), 1:(ncol(manova_df)-1))]

# Round numeric columns for readability
num_cols <- sapply(manova_df, is.numeric)
manova_df[, num_cols] <- round(manova_df[, num_cols], 3)

# Create a nice LaTeX table
knitr::kable(manova_df,
             caption = "MANOVA Test of Geological Structure Groups \\label{tab:groupsManova}",
             align = "c",
             booktabs = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE)
```
To assess whether the predefined geostructural groups are verified by the water 
chemistry data, we began with a formal test of multivariate mean differences. A 
MANOVA on the log-transformed variables produced a p-value of 0.057, which can be seen in Table \@ref(tab:groupsManova). This 
provides only weak evidence that the group mean vectors differ, suggesting 
that while some differences exist, they are not pronounced enough to be 
considered statistically significant at conventional levels.

```{r  groupVarCheck, fig.cap="Visual Check of Group Covariance", echo=FALSE}
lda_data <- data.frame(geoStruct = data$geoStruct, X_log_matrix)
lda_fit <- lda(geoStruct ~ ., data = lda_data)
lda_scores <- predict(lda_fit)$x

plot_data <- data.frame(lda_scores, Group = as.factor(lda_data$geoStruct))

ggplot(plot_data, aes(x = LD1, y = LD2, color = Group)) +
  geom_point(size = 3) +
  stat_ellipse(level = 0.95) +
  labs(title = "Visual Check of Group Covariance",
       x = "Linear Discriminant 1",
       y = "Linear Discriminant 2") +
  theme_minimal()
```

We can see distinct shapes and orientations in the ellipses 
representing the covariance of the groups in the LDA plot in Figure \@ref(fig:groupVarCheck). Given the clear differences between
these groups, the covariance matrices of the groups cannot be equal. LDA is therefore
not appropriate for this data. The assumption of equal covariance is clearly 
violated when looking at the distinction in the shape and orientation between each 
group.

As an alternative, we adopted for the Naive Bayes classifier. Unlike LDA, Naive Bayes does not require estimation of full covariance matrices, and instead assumes conditional independence of the variables within each class. This makes it more appropriate for datasets with small and unbalanced groups such as ours, where some geostructural categories contained as few as five observations. We fitted the Naive Bayes model to the log-transformed variables and evaluated performance using leave-one-out cross-validation to provide a fair estimate of classification accuracy.

Although we did not have external prior probabilities for the geostructural categories, Naive Bayes estimates them from the observed class frequencies in the sample. This corresponds to assuming that the sample is representative of the population proportions. Alternatively, one could impose equal priors to reflect an uninformative prior belief. In either case, the classification rule remains valid, and our results reflect how well the chemical profiles align with the predefined groups under these assumptions.

```{r echo=FALSE}
y  <- factor(data$geoStruct)
Xl <- scale(as.data.frame(X_log_matrix))
# Leave-One-Out Cross-Validation
n <- nrow(Xl); pred <- factor(rep(NA,n), levels=levels(y))
for(i in 1:n){
  fit_i <- naiveBayes(x=Xl[-i,], y=y[-i])
  pred[i] <- predict(fit_i, newdata=Xl[i,,drop=FALSE])
}
# compute confusion matrix
cm <- caret::confusionMatrix(pred, y)
```

```{r confusionMatrix, fig.cap="Confusion Matrix for Naive Bayes Classification", echo=FALSE}
y  <- factor(data$geoStruct)
Xl <- scale(as.data.frame(X_log_matrix))
# Leave-One-Out Cross-Validation
n <- nrow(Xl); pred <- factor(rep(NA,n), levels=levels(y))
for(i in 1:n){
  fit_i <- naiveBayes(x=Xl[-i,], y=y[-i])
  pred[i] <- predict(fit_i, newdata=Xl[i,,drop=FALSE])
}

# ensure factors have same levels
pred <- factor(pred, levels = levels(y))
y <- factor(y, levels = levels(y))

# create confusion matrix table
cm_table <- table(Predicted = pred, True = y) %>%
  as.data.frame() %>%
  rename(Freq = Freq)

# square matrix: make sure levels are respected for plotting
cm_table$Predicted <- factor(cm_table$Predicted, levels = levels(y))
cm_table$True <- factor(cm_table$True, levels = levels(y))

ggplot(cm_table, aes(x = True, y = Predicted, fill = Freq)) +
  geom_tile(color = NA, size = 0.8) +
  geom_text(aes(label = Freq), size = 6, family = "Times", fontface = "bold") +
  scale_fill_gradient(low = "white", high = "#046C9A") +
  labs(
    x = "True Class",
    y = "Predicted Class",
    title = "LOOCV Confusion Matrix"
  ) +
  theme_minimal(base_family = "Times") +
  theme(
    plot.title = element_text(size = 20, face = "bold"),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 14),
    panel.grid = element_blank()
  ) +
  coord_fixed() 
```

```{r fig.cap="Naive Bayes Classification Statistics", echo=FALSE}
# Extract Accuracy as a plain numeric
acc <- unname(round(cm$overall["Accuracy"], 2))

# Manually create the table values
overall_df <- data.frame(
  Statistic = c("Accuracy", "No-Information Rate"),
  Value = c(acc, 0.40)
)

# Table
kable(overall_df,
      caption = "Naive Bayes Overall Classification Statistics \\label{tab:classificationOverallStats}",
      format = "latex",
      align = c("l", "c"),
      digits = 2) %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"),
                full_width = FALSE) %>%
  row_spec(0, bold = TRUE)
```

```{r fig.cap="Naive Bayes Classification: Class-wise Statistics", echo=FALSE}
# Convert cm$byClass to data frame
byclass_df <- as.data.frame(cm$byClass)

# Add class labels
byclass_df$Class <- rownames(byclass_df)

# Reshape so that classes are columns, stats are rows
byclass_wide <- byclass_df %>%
  pivot_longer(
    cols = -Class,
    names_to = "Statistic",
    values_to = "Value"
  ) %>%
  pivot_wider(
    names_from = Class,
    values_from = Value
  )

# Round for neatness
byclass_wide[,-1] <- round(byclass_wide[,-1], 3)

# Pretty wide table: rows = stats, cols = classes
kable(byclass_wide,
      caption = "Naive Bayes Class-wise Statistics \\label{tab:classificationByClassStats}",
      format = "latex",
      align = c("l", rep("c", ncol(byclass_wide)-1)),
      booktabs = TRUE,
      digits = 3) %>%
  kable_styling(latex_options = c("HOLD_position", "scale_down"),
                full_width = FALSE,
                font_size = 11) %>%
  row_spec(0, bold = TRUE)
```

As we can see in the overall classification statistics in Table \@ref(tab:classificationOverallStats), the model achieved an overall accuracy of 50 percent, which is higher than the no-information rate of 40 percent but still modest. The Kappa statistic of 0.29 suggests only fair agreement between the predicted and true classes. The by class statistics in Table \@ref(tab:classificationByClassStats), the classification performance varied across groups. Karstic terrains (Class 2) and Metamorphic regions (Class 4) were the best recognised categories, with balanced accuracies of 0.81 and 0.74 respectively, indicating that their chemical profiles are relatively distinctive. Hydrological Basins (Class 1), on the other hand, were poorly distinguished and often misclassified as Volcanogenic Massifs, as seen in the confusion matrix in Table \@ref(fig:confusionMatrix). Volcanogenic Massifs themselves, despite being the largest group, were only moderately well classified, with a balanced accuracy of 0.53.

These results suggest that the groups, the geostructural categories, are only partially verified by the data. Some groups do exhibit clear multivariate chemical signatures, allowing them to be separated reasonably well, while others show substantial overlap that prevents reliable classification. In particular, the difficulty in separating Hydrological Basins from Volcanogen Massifs implies that the water chemistry of these groups is not sufficiently distinct. Overall, the analysis provides evidence that geological structure does influence chemical composition, but the effect is not strong enough across all groups for the classification to be considered fully verified. The geostructural groupings are therefore only partially confirmed by the data.

# **Conclusion**

Despite working with a reduced dataset compared to the initial study, we managed
to replicate some of the analysis of the study. Applying PCA to the data
found that four PCs was sufficient for the data, and the first two PCs, 
accounting for 70% of the variance, were characterised by the same variables as 
the study's PCs (PC1 by mineralisation and PC2 by water hardness). To improve on 
the parsimony of these results, we applied factor analysis to the data and found
that four factors provided a simpler and more accurate model while still working
with the same characteristic variable combinations (mineralisation, water hardness,
chloric waters, and sulfate waters). These for factors accounted for 79% of the
variance, which is comparable with the PCA results and preferable for its 
simpler modelling.

Our analysis also attempted to verify the geostructural groups used in the 
study. The unbalanced nature of the data made these groups difficult to 
verify using LDA, so we used the Naive Bayes classifier, finding only a partial
confirmation of the groups by the data, with a model accuracy of 50%, although
for this was higher for Karstic Terrains and Metamorphic Regions, which have
the most distinctive chemical profiles. Hydrological Basins and Volgagenic 
Massifs were difficult to accurately classify separately, indicating that
they are not distinguishable by unique chemical profiles.

## References
